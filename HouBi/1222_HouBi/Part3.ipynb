{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300966cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"將tensorflow檔轉成tensorflow lite，使機器負載量變小\"\"\"\n",
    "from tensorflow import lite\n",
    "from tensorflow.keras import models\n",
    "\n",
    "# Parameters\n",
    "keras_model_filename = './h5_normalize/recording9_fbank.h5' #訓練好的模型\n",
    "tflite_filename = './tflite_normalize/recording9_fbank.tflite' #預建置檔案\n",
    "\n",
    "# Convert model to TF Lite model\n",
    "model = models.load_model(keras_model_filename) #載入本來的模型\n",
    "converter = lite.TFLiteConverter.from_keras_model(model) #將模型載入轉換器\n",
    "tflite_model = converter.convert() #進行轉換\n",
    "open(tflite_filename, 'wb').write(tflite_model) #輸出轉換後的模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c31dc816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backgroundNoise\n",
      "MAX:0.9948199391365051\n",
      "的\n",
      "MAX:0.9882595539093018\n",
      "backgroundNoise\n",
      "MAX:0.9999996423721313\n",
      "backgroundNoise\n",
      "MAX:0.9775601625442505\n",
      "嗯\n",
      "MAX:0.9849178194999695\n",
      "你\n",
      "MAX:0.9983115196228027\n",
      "其他\n",
      "MAX:0.829176664352417\n",
      "backgroundNoise\n",
      "MAX:0.9903884530067444\n",
      "backgroundNoise\n",
      "MAX:1.0\n",
      "backgroundNoise\n",
      "MAX:0.9999833106994629\n",
      "backgroundNoise\n",
      "MAX:0.9870778322219849\n",
      "其他\n",
      "MAX:0.7135568261146545\n",
      "你\n",
      "MAX:0.8458034992218018\n",
      "其他\n",
      "MAX:0.9446187019348145\n",
      "你\n",
      "MAX:0.9990611672401428\n",
      "你\n",
      "MAX:0.8070201277732849\n",
      "ㄟ\n",
      "MAX:0.8645926117897034\n",
      "backgroundNoise\n",
      "MAX:0.9998080134391785\n",
      "ㄏㄧㄡ\n",
      "MAX:0.9747885465621948\n",
      "我\n",
      "MAX:0.9314422607421875\n",
      "ㄟ\n",
      "MAX:0.9985009431838989\n",
      "你\n",
      "MAX:0.9999996423721313\n",
      "你\n",
      "MAX:0.9999996423721313\n",
      "backgroundNoise\n",
      "MAX:0.7746793627738953\n",
      "backgroundNoise\n",
      "MAX:0.9893921613693237\n",
      "ㄏㄧㄡ\n",
      "MAX:0.9856022000312805\n",
      "其他\n",
      "MAX:0.8326053619384766\n",
      "嗯\n",
      "MAX:1.0\n",
      "那\n",
      "MAX:0.9875824451446533\n",
      "其他\n",
      "MAX:0.9861457943916321\n",
      "backgroundNoise\n",
      "MAX:0.9979947805404663\n",
      "ㄟ\n",
      "MAX:0.9999992847442627\n",
      "ㄟ\n",
      "MAX:0.9999915361404419\n",
      "backgroundNoise\n",
      "MAX:0.9992175102233887\n",
      "ㄟ\n",
      "MAX:0.8044243454933167\n",
      "ㄟ\n",
      "MAX:0.9932419657707214\n",
      "的\n",
      "MAX:0.8258617520332336\n",
      "backgroundNoise\n",
      "MAX:0.9999061822891235\n",
      "好\n",
      "MAX:0.981512188911438\n",
      "的\n",
      "MAX:0.9546594619750977\n",
      "我\n",
      "MAX:0.9370457530021667\n",
      "我\n",
      "MAX:0.973994791507721\n",
      "好\n",
      "MAX:0.9950941801071167\n",
      "啦\n",
      "MAX:0.9520558714866638\n",
      "backgroundNoise\n",
      "MAX:0.9998842477798462\n",
      "backgroundNoise\n",
      "MAX:0.9595224857330322\n",
      "那\n",
      "MAX:0.977348804473877\n",
      "backgroundNoise\n",
      "MAX:0.7618288993835449\n",
      "ㄟ\n",
      "MAX:0.9615232944488525\n",
      "backgroundNoise\n",
      "MAX:0.9999995231628418\n",
      "backgroundNoise\n",
      "MAX:1.0\n",
      "ㄟ\n",
      "MAX:0.9993220567703247\n",
      "ㄟ\n",
      "MAX:0.94576495885849\n",
      "你\n",
      "MAX:0.9934061765670776\n",
      "backgroundNoise\n",
      "MAX:0.9999926090240479\n",
      "ㄏㄧㄡ\n",
      "MAX:0.9972973465919495\n",
      "其他\n",
      "MAX:0.7019209265708923\n",
      "我\n",
      "MAX:0.8596823811531067\n",
      "我\n",
      "MAX:0.9916483163833618\n",
      "我\n",
      "MAX:0.9995388984680176\n",
      "嗯\n",
      "MAX:0.999998927116394\n",
      "你\n",
      "MAX:0.967311680316925\n",
      "ㄟ\n",
      "MAX:0.9868029952049255\n",
      "我\n",
      "MAX:0.80283522605896\n",
      "其他\n",
      "MAX:0.9867357015609741\n",
      "backgroundNoise\n",
      "MAX:0.9941535592079163\n",
      "嗯\n",
      "MAX:0.9996016621589661\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bb1a56670af9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#即時\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import python_speech_features\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "#import RPi.GPIO as GPIO\n",
    "\n",
    "# Parameters\n",
    "word_threshold = 0.7 #預測值>0.7\n",
    "rec_duration = 0.5 #每一段錄音持續時間\n",
    "sample_rate = 16000 #取樣率(依MIC不同而改變)\n",
    "num_channels = 1 #音訊深度\n",
    "model_path = './tflite_normalize/recording9_fbank.tflite'\n",
    "words = ['backgroundNoise', 'ㄏㄧㄡ', 'ㄟ', '他', '你', '其他', '吼', '啦', '嗯', '好', '我', '的', '著', '那', '阿']\n",
    "\n",
    "# Sliding window\n",
    "window = np.zeros(8000)#取樣音頻數據變數\n",
    "\n",
    "# GPIO \n",
    "#GPIO.setwarnings(False)\n",
    "#GPIO.setmode(GPIO.BOARD)\n",
    "#GPIO.setup(8, GPIO.OUT, initial=GPIO.LOW)\n",
    "\n",
    "# Load model (interpreter)\n",
    "interpreter = tf.lite.Interpreter(model_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# This gets called every 0.5 seconds\n",
    "def sd_callback(rec, frames, time, status):\n",
    "\n",
    "    #GPIO.output(led_pin, GPIO.LOW)\n",
    "    \n",
    "    # Notify if errors\n",
    "    if status:\n",
    "        print('Error:', status)\n",
    "    \n",
    "    # Remove 2nd dimension from recording sample\n",
    "    #壓縮成1D張量\n",
    "    rec = np.squeeze(rec)\n",
    "\n",
    "    #將音訊輸入到window\n",
    "    window = rec\n",
    "    S = np.abs(librosa.stft(window)) #將整個window音訊做stft，並轉成絕對值\n",
    "    \n",
    "    if np.sum(S) >= 3500: #判斷S的總和是否>=3500，如果>=3500，代表有講話\n",
    "        \n",
    "        window = window.astype(np.float)\n",
    "\n",
    "        window = (window - window.mean()) / (window.max() - window.min())\n",
    "    \n",
    "        # Compute features\n",
    "        features = python_speech_features.base.logfbank(window,\n",
    "                                                        samplerate=16000,\n",
    "                                                        winlen=0.025,\n",
    "                                                        winstep=0.01,\n",
    "                                                        nfilt=26,\n",
    "                                                        nfft=512,\n",
    "                                                        lowfreq=0,\n",
    "                                                        highfreq=None,\n",
    "                                                        preemph=0.97)\n",
    "        \n",
    "        # Make prediction from model\n",
    "        in_tensor = np.float32(features.reshape(1, features.shape[0], features.shape[1], 1))\n",
    "        #設定輸入張量\n",
    "        interpreter.set_tensor(input_details[0]['index'], in_tensor)\n",
    "        #進行預測\n",
    "        interpreter.invoke()\n",
    "        #取得輸出張量\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        val = output_data[0]#取得預測值\n",
    "        val = val.tolist() #np.ndarray to list\n",
    "        list_val_max = max(val) #取得最大值\n",
    "        list_val_maxIndex = val.index(max(val)) #取得最大值的索引  \n",
    "        \n",
    "        if(list_val_max > word_threshold):\n",
    "            print(words[list_val_maxIndex])#輸出相對應的字詞\n",
    "            print(\"MAX:\" + str(list_val_max))#輸出預測值當中最大的值\n",
    "    \n",
    "# Start streaming from microphone\n",
    "with sd.InputStream(channels=num_channels,\n",
    "                    samplerate=sample_rate,\n",
    "                    blocksize=int(sample_rate * rec_duration),\n",
    "                    callback=sd_callback):\n",
    "    while True:\n",
    "        \n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d95154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嗯 0分0.5秒 預測值:0.9999884366989136\n",
      "嗯 0分0.75秒 預測值:1.0\n",
      "嗯 0分1.0秒 預測值:0.9999039173126221\n"
     ]
    }
   ],
   "source": [
    "#非即時\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import python_speech_features\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "\n",
    "def sound(window,s,m):\n",
    "\n",
    "    S = np.abs(librosa.stft(window)) #將整個window音訊做stft，並轉成絕對值\n",
    "    \n",
    "    if np.sum(S) >= 3500: #判斷S的總和是否>=3500，如果>=3500，代表有明顯的聲音\n",
    "        window = window.astype(np.float)\n",
    "\n",
    "        window = (window - window.mean()) / (window.max() - window.min())\n",
    "\n",
    "        features = python_speech_features.base.logfbank(window,\n",
    "                                                        samplerate=16000,\n",
    "                                                        winlen=0.025,\n",
    "                                                        winstep=0.01,\n",
    "                                                        nfilt=26,\n",
    "                                                        nfft=512,\n",
    "                                                        lowfreq=0,\n",
    "                                                        highfreq=None,\n",
    "                                                        preemph=0.97)\n",
    "        \n",
    "        # Make prediction from model\n",
    "        in_tensor = np.float32(features.reshape(1, features.shape[0], features.shape[1], 1))\n",
    "        #設定輸入張量\n",
    "        interpreter.set_tensor(input_details[0]['index'], in_tensor)\n",
    "        #進行預測\n",
    "        interpreter.invoke()\n",
    "        #取得輸出張量\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        val = output_data[0]#取得預測值\n",
    "        val = val.tolist() #np.ndarray to list\n",
    "        list_val_max = max(val) #取得最大值\n",
    "        list_val_maxIndex = val.index(max(val)) #取得最大值的索引  \n",
    "        \n",
    "        if(list_val_max > 0.7):\n",
    "            print(words[list_val_maxIndex] + \" \" + str(m) + \"分\" + str(s) + \"秒\" + \" 預測值:\" + str(list_val_max))#輸出相對應的字詞\n",
    "        #if(best_candidate_probability > 0.7): # treshold\n",
    "        #    if(str(all_targets[best_candidate_index]) != \"backgroundNoise\"):\n",
    "        #        data.append(str(all_targets[best_candidate_index]) + \" \" + str(m) + \"分\" + str(s) + \"秒\" + \" 預測值:\" + str(best_candidate_probability)) \n",
    "        \n",
    "#main\n",
    "# Parameters\n",
    "model_path = './tflite_normalize/recording9_fbank.tflite'\n",
    "words = ['backgroundNoise', 'ㄏㄧㄡ', 'ㄟ', '他', '你', '其他', '吼', '啦', '嗯', '好', '我', '的', '著', '那', '阿']\n",
    "\n",
    "data = []\n",
    "start = 0 #一開始的索引值\n",
    "end = 4000 #一開始的索引值\n",
    "s = 0 #秒\n",
    "m = 0 #分\n",
    "duration = 60 #讀音檔的總時間\n",
    "sample_rate = 16000 #取樣率\n",
    "\n",
    "#載入音檔\n",
    "y, sr = librosa.load(\"./TestWAV/TEST.wav\",sr=sample_rate) \n",
    "\n",
    "#用0填滿時間，以讓滑動視窗都有東西\n",
    "total_sec = len(y) / 16000 #算音檔總時間\n",
    "if total_sec < 1: #如果音檔<1s\n",
    "    new_y = np.zeros(16000) #new_y補足1s\n",
    "    new_y[0:len(y)] = y #將原先的音訊載入到新的陣列\n",
    "elif total_sec - (int(total_sec)) != 0: #如果音檔非整數秒，ex:原先音訊長度1.2s ，1.2 - 1 != 0 ， 將長度補到2s\n",
    "    total_sec = (int(total_sec) + 1) #新時間為原時間整數+1\n",
    "    new_y = np.zeros(total_sec * 16000) #補足到整數秒\n",
    "    new_y[0:len(y)] = y #將原先的音訊載入到新的陣列\n",
    "else:\n",
    "    new_y = y\n",
    "\n",
    "# Sliding window\n",
    "window = np.zeros(8000)#取樣音頻數據變數\n",
    "\n",
    "# Load model (interpreter)\n",
    "interpreter = tf.lite.Interpreter(model_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "while True:\n",
    "    s = s + 0.25 #增加秒數\n",
    "    if(s >= 60): #60秒 轉成 1分\n",
    "        s = 0\n",
    "        m = m + 1\n",
    "\n",
    "    window[:4000] = window[4000:] #把音訊載入window\n",
    "    window[4000:] = new_y[start:end] #把音訊載入window\n",
    "    \n",
    "    sound(window,s,m) #呼叫sound()\n",
    "\n",
    "    if(end == len(new_y)): #如果移動到最後，break\n",
    "        break\n",
    "    \n",
    "    start = start + 4000 #向後移動\n",
    "    end = end + 4000 #向後移動    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03bcaef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
